{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "\n",
    "from options import args_parser\n",
    "from utils import exp_details, get_dataset, average_weights\n",
    "from update import LocalUpdate, test_inference\n",
    "from models import MLP, CNNMnist, CNNFashion_Mnist, CNNCifar, AutoencoderMNIST\n",
    "from sampling import dominant_label_sampling\n",
    "from resnet import resnet20\n",
    "\n",
    "\n",
    "def get_model(args, train_dataset, device):\n",
    "    if args.supervision:\n",
    "        # Supervised learning\n",
    "        if args.model == \"resnet\":\n",
    "            if args.dataset == \"cifar\":\n",
    "                model = resnet20()\n",
    "            else:\n",
    "                exit(\"ResNet only implemented for CIFAR-10 dataset\")\n",
    "        elif args.model == \"cnn\":\n",
    "            # Convolutional neural netork\n",
    "            if args.dataset == \"mnist\":\n",
    "                model = CNNMnist(num_channels=args.num_channels, num_classes=args.num_classes)\n",
    "            elif args.dataset == \"fmnist\":\n",
    "                model = CNNFashion_Mnist()\n",
    "            elif args.dataset == \"cifar\":\n",
    "                model = CNNCifar(num_classes=args.num_classes)\n",
    "\n",
    "        elif args.model == \"mlp\":\n",
    "            # Multi-layer preceptron\n",
    "            img_size = train_dataset[0][0].shape\n",
    "            len_in = 1\n",
    "            for x in img_size:\n",
    "                len_in *= x\n",
    "            model = MLP(dim_in=len_in, dim_hidden=64, dim_out=args.num_classes)\n",
    "        else:\n",
    "            exit(\"Error: unrecognized model\")\n",
    "    else:\n",
    "        # Self-supervised learning\n",
    "        if args.model == \"autoencoder\":\n",
    "            # Autoencoder with transpose convolutions\n",
    "            if args.dataset == \"mnist\":\n",
    "                model = AutoencoderMNIST(args=args)\n",
    "\n",
    "        else:\n",
    "            exit(\"Error: unrecognized unsupervised model\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    epochs = 80\n",
    "    optimal_epochs = 10\n",
    "\n",
    "    # Parse, validate, and print arguments\n",
    "    args = args_parser()\n",
    "    exp_details(args)\n",
    "\n",
    "    # Set random seed for numpy\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    data_dir = f\"../data/{args.dataset}/\"\n",
    "    apply_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_dataset = datasets.MNIST(data_dir, train=True, download=True, transform=apply_transform)\n",
    "    test_dataset = datasets.MNIST(data_dir, train=False, download=True, transform=apply_transform)\n",
    "\n",
    "    base_model = get_model(args, train_dataset, device)\n",
    "    optimal_model = copy.deepcopy(base_model)\n",
    "    global_model = copy.deepcopy(base_model)\n",
    "    local_models = [copy.deepcopy(base_model) for _ in range(args.num_users)]\n",
    "    dict_users = dominant_label_sampling(train_dataset, num_users=100, gamma=0.1, print_labels=False)\n",
    "\n",
    "    print(\"Training optimal model...\")\n",
    "    epoch_optimal_params = []\n",
    "    \n",
    "    acc, loss = test_inference(supervision=True, device=\"cuda\", model=optimal_model, test_dataset=test_dataset, test_fraction=1)\n",
    "    optimal_params = torch.cat([p.flatten() for p in optimal_model.parameters()]).detach().cpu().numpy()\n",
    "    epoch_optimal_params.append(optimal_params)\n",
    "    print(f\"Accuracy of optimal model: {acc}\")\n",
    "\n",
    "    for _ in tqdm(range(optimal_epochs)):\n",
    "        local_update = LocalUpdate(\n",
    "            train_dataset,\n",
    "            range(50_000),\n",
    "            args.local_ep,\n",
    "            args.local_bs,\n",
    "            args.lr,\n",
    "            args.optimizer,\n",
    "            args.supervision,\n",
    "            device,\n",
    "        )\n",
    "        w, loss = local_update.update_weights(optimal_model)\n",
    "\n",
    "        acc, loss = test_inference(supervision=True, device=\"cuda\", model=optimal_model, test_dataset=test_dataset, test_fraction=1)\n",
    "        print(f\"Accuracy of optimal model: {acc}\")\n",
    "        optimal_params = torch.cat([p.flatten() for p in optimal_model.parameters()]).detach().cpu().numpy()\n",
    "        epoch_optimal_params.append(optimal_params)\n",
    "    \n",
    "    print(\"Training client fitting models...\")\n",
    "    epoch_user_params = []\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        user_params = []\n",
    "        curr_users = np.random.choice(args.num_users, int(args.num_users * args.frac))\n",
    "        for usr in curr_users:\n",
    "            local_model = local_models[usr]\n",
    "\n",
    "            local_update = LocalUpdate(\n",
    "                train_dataset,\n",
    "                dict_users[usr],\n",
    "                args.local_ep,\n",
    "                args.local_bs,\n",
    "                args.lr,\n",
    "                args.optimizer,\n",
    "                args.supervision,\n",
    "                device,\n",
    "            )\n",
    "            w, loss = local_update.update_weights(local_model)\n",
    "\n",
    "            \n",
    "        for i, user_samples in dict_users.items():\n",
    "            local_model = local_models[i]\n",
    "            params = torch.cat([p.flatten() for p in local_model.parameters()]).detach().cpu().numpy()\n",
    "            user_params.append(params)\n",
    "        epoch_user_params.append(user_params)\n",
    "\n",
    "        local_model_weights = [local_models[usr].state_dict() for usr in curr_users]\n",
    "        avg_weights = average_weights(local_model_weights)\n",
    "        global_model.load_state_dict(avg_weights)\n",
    "        for model in local_models:\n",
    "            model.load_state_dict(avg_weights)\n",
    "\n",
    "        acc, loss = test_inference(supervision=True, device=\"cuda\", model=global_model, test_dataset=test_dataset, test_fraction=1)\n",
    "        print(f\"Accuracy of global model: {acc}\")\n",
    "\n",
    "        user_params = []\n",
    "        for i, user_samples in dict_users.items():\n",
    "            local_model = local_models[i]\n",
    "            params = torch.cat([p.flatten() for p in local_model.parameters()]).detach().cpu().numpy()\n",
    "            user_params.append(params)\n",
    "        epoch_user_params.append(user_params)\n",
    "    \n",
    "\n",
    "    # PCA for fitting model parameters\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(epoch_optimal_params)\n",
    "    pca.fit([params for user_params in epoch_user_params for params in user_params])\n",
    "\n",
    "    epoch_optimal_params_pca = pca.transform(epoch_optimal_params)\n",
    "    \n",
    "    epoch_user_params_pca = np.array([pca.transform(user_params) for user_params in epoch_user_params])\n",
    "\n",
    "    # tsne = TSNE() \n",
    "    # epoch_all_params = tsne.fit_transform([*epoch_optimal_params, *[user_params for user_params in epoch_user_params]])\n",
    "    # epoch_optimal_params_tsne = tsne.fit(epoch_all_params[:len(optimal_epochs)])\n",
    "    # epoch_user_params_tsne = tsne.fit(epoch_all_params[:len(optimal_epochs)])\n",
    "\n",
    "    # labels = [\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "    labels = range(10)\n",
    "\n",
    "    all_x = [*epoch_optimal_params_pca[:, 0], *epoch_user_params_pca[:, :, 0].flatten()]\n",
    "    all_y = [*epoch_optimal_params_pca[:, 1], *epoch_user_params_pca[:, :, 1].flatten()]\n",
    "\n",
    "    xlim = (min(all_x), max(all_x))\n",
    "    ylim = (min(all_y), max(all_y))\n",
    "\n",
    "    for epoch in range(epochs * 2):\n",
    "        fig, ax = plt.subplots()\n",
    "        pth = ax.scatter(epoch_optimal_params_pca[:, 0], epoch_optimal_params_pca[:, 1], c=range(optimal_epochs + 1), cmap=\"plasma\")\n",
    "        fig.colorbar(pth)\n",
    "\n",
    "        ax.scatter(epoch_user_params_pca[epoch, :, 0], epoch_user_params_pca[epoch, :, 1], c=\"g\")\n",
    "        ax.set_title(\"Principal Components of MNIST Models\")\n",
    "        ax.set_xlabel(\"Principal Component 1\")\n",
    "        ax.set_ylabel(\"Principal Component 2\")\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        plt.savefig(f\"pca_models_epoch_{epoch}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = '/home/srajani/fed_ssl/Self_Supervised_Federated_Learning/images'\n",
    "video_name = 'video.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "images.sort(key=lambda a: int(a.split(\"_\")[-1].split(\".\")[0]))\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 1, (width, height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
