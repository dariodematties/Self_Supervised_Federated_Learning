{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723bebee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_989653/3886941740.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margs_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexp_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_distribution_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelDistributionDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fed_ssl/Self_Supervised_Federated_Learning/src/utils/label_distribution_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.options import args_parser\n",
    "from utils.utils import exp_details, get_model\n",
    "from utils.label_distribution_dataset import LabelDistributionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args_parser(default=True)\n",
    "\n",
    "args.local_ep = 5\n",
    "args.lr = 0.00001\n",
    "args.supervision = True\n",
    "\n",
    "exp_details(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = get_model(args.arch, args.dataset, \"cpu\")\n",
    "base_model_path = os.path.join(args.data_path, f\"base_model_{args.dataset}.pth\")\n",
    "torch.save(base_model, base_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa19b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LabelDistributionDataset(args.dataset, args.local_ep, args.local_bs, args.lr, args.optimizer, args.supervision, True, args.data_dir, base_model_path, \"cuda\")\n",
    "test_dataset = LabelDistributionDataset(args.dataset, args.local_ep, args.local_bs, args.lr, args.optimizer, args.supervision, False, args.data_dir, base_model_path, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of samples in train set: {len(train_dataset)}\")\n",
    "print(f\"Number of samples in test set: {len(test_dataset)}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "for X, y in train_dataloader:\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributionPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Linear(10, 1000)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(8):\n",
    "            self.hidden_layers.append(nn.Sequential(\n",
    "                nn.Linear(1000, 1000),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "        self.output_layer = nn.Linear(1000, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.relu(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bbcf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, device):\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss\n",
    "    train_loss /= num_batches\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn, device):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "model_save_path = \"../save/distribution_predictor_model.pth\"\n",
    "\n",
    "model = DistributionPredictor()\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "epochs = 500\n",
    "for t in tqdm(range(epochs)):\n",
    "    test_loss = test(test_dataloader, model, loss_fn, device)\n",
    "    test_losses.append(test_loss)\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "print(\"Done!\")\n",
    "print(f\"Final test loss: {test_losses[-1]:.5f}\")\n",
    "print(f\"Final train loss: {train_losses[-1]:.5f}\")\n",
    "\n",
    "torch.save(model, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "\n",
    "plt.xlabel(\"Training Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs. Training Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ccc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "model = torch.load(model_save_path)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        for a, b in zip(pred.cpu().numpy(), y.cpu().numpy()):\n",
    "            print(a, b)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = 15\n",
    "\n",
    "fig, axs = plt.subplots(num_plots, 2, figsize=(8, num_plots * 2))\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "colors = [cmap(i) for i in range(10)]\n",
    "\n",
    "for i in range(num_plots):\n",
    "    axs[i][0].bar(range(10), pred[i].cpu().numpy(), color=colors)\n",
    "    axs[i][0].set_ylim(0, 1)\n",
    "    axs[i][0].set_xticks([])\n",
    "    axs[i][0].set_yticks([])\n",
    "    axs[i][1].bar(range(10), y[i].cpu().numpy(), color=colors)\n",
    "    axs[i][1].set_ylim(0, 1)\n",
    "    axs[i][1].set_xticks([])\n",
    "    axs[i][1].set_yticks([])\n",
    "    \n",
    "axs[0, 0].set_title(\"Prediction\")\n",
    "axs[0, 1].set_title(\"Ground Truth\")\n",
    "\n",
    "plt.savefig(\"Distribution Comparison CIFAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2622602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f60b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
